//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32267302
// Cuda compilation tools, release 12.0, V12.0.140
// Based on NVVM 7.0.1
//

.version 8.0
.target sm_52
.address_size 64

	// .globl	histogram_i32_kernel

.visible .entry histogram_i32_kernel(
	.param .u64 histogram_i32_kernel_param_0,
	.param .u64 histogram_i32_kernel_param_1,
	.param .u32 histogram_i32_kernel_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<8>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [histogram_i32_kernel_param_0];
	ld.param.u64 	%rd2, [histogram_i32_kernel_param_1];
	ld.param.u32 	%r2, [histogram_i32_kernel_param_2];
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r3, %r4, %r5;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB0_2;

	cvta.to.global.u64 	%rd3, %rd1;
	mul.wide.s32 	%rd4, %r1, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.u32 	%r6, [%rd5];
	cvta.to.global.u64 	%rd6, %rd2;
	mul.wide.s32 	%rd7, %r6, 4;
	add.s64 	%rd8, %rd6, %rd7;
	atom.global.add.u32 	%r7, [%rd8], 1;

$L__BB0_2:
	ret;

}
	// .globl	histogram_i32x4_kernel
.visible .entry histogram_i32x4_kernel(
	.param .u64 histogram_i32x4_kernel_param_0,
	.param .u64 histogram_i32x4_kernel_param_1,
	.param .u32 histogram_i32x4_kernel_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<19>;
	.reg .b64 	%rd<15>;


	ld.param.u64 	%rd1, [histogram_i32x4_kernel_param_0];
	ld.param.u64 	%rd2, [histogram_i32x4_kernel_param_1];
	ld.param.u32 	%r2, [histogram_i32x4_kernel_param_2];
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r6, %r4, %r3, %r5;
	shl.b32 	%r1, %r6, 2;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB1_2;

	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	mul.wide.s32 	%rd5, %r1, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.v4.u32 	{%r7, %r8, %r9, %r10}, [%rd6];
	mul.wide.s32 	%rd7, %r7, 4;
	add.s64 	%rd8, %rd3, %rd7;
	atom.global.add.u32 	%r15, [%rd8], 1;
	mul.wide.s32 	%rd9, %r8, 4;
	add.s64 	%rd10, %rd3, %rd9;
	atom.global.add.u32 	%r16, [%rd10], 1;
	mul.wide.s32 	%rd11, %r9, 4;
	add.s64 	%rd12, %rd3, %rd11;
	atom.global.add.u32 	%r17, [%rd12], 1;
	mul.wide.s32 	%rd13, %r10, 4;
	add.s64 	%rd14, %rd3, %rd13;
	atom.global.add.u32 	%r18, [%rd14], 1;

$L__BB1_2:
	ret;

}

